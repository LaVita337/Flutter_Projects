{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgkYc8PFKYPV",
    "outputId": "9f206ae9-0d13-4045-bacb-8cdb7abf397b"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmYxijGneQZV",
    "outputId": "13f5394a-b8fa-4d28-a10e-e305722dc4cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CLIP_prefix_caption'...\n",
      "remote: Enumerating objects: 167, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 167 (delta 77), reused 73 (delta 73), pack-reused 76\u001b[K\n",
      "Receiving objects: 100% (167/167), 2.18 MiB | 13.92 MiB/s, done.\n",
      "Resolving deltas: 100% (82/82), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rmokady/CLIP_prefix_caption.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPDdlU4PgVCc",
    "outputId": "a3e0a451-f579-4f4c-e209-0d5fee16ae56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/'\n",
      "/home/i15project23\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2023.10.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from ftfy) (0.2.10)\n",
      "Installing collected packages: tqdm, regex, ftfy\n",
      "Successfully installed ftfy-6.1.1 regex-2023.10.3 tqdm-4.66.1\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-dkzrgrbq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-dkzrgrbq\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from clip==1.0) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from clip==1.0) (4.66.1)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.10)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from torch->clip==1.0) (4.7.1)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (65.6.3)\n",
      "Requirement already satisfied: wheel in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.38.4)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.5.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.8/136.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=7a67441547378e1be3aa06c2512883419dbf91a2bc20a60c0f5db30e8758a9da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cmokfldl/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
      "Successfully built clip\n",
      "Installing collected packages: urllib3, pillow, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, charset-normalizer, requests, nvidia-cudnn-cu11, torch, torchvision, clip\n",
      "Successfully installed charset-normalizer-3.3.2 clip-1.0 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pillow-9.5.0 requests-2.31.0 torch-1.13.1 torchvision-0.14.1 urllib3-2.0.7\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAmWAud7hktV",
    "outputId": "9dcaeb94-d3d7-4155-b2f5-98b9b5b25dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive ↖here would be simpler if you are the creator of a notebook. Maybe you can create a new notebook and copy the cells.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fq_lJoD0ik5_",
    "outputId": "e9ec3650-ccbb-44bd-a0fc-7d90d2535771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/CLIP_prefix_caption/'\n",
      "/home/i15project23\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorflow) (4.7.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorflow) (23.2)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.4 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.59.2 h5py-3.8.0 keras-2.11.0 libclang-16.0.6 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 werkzeug-2.2.3 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 06:36:38.555688: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 06:36:38.691644: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-17 06:36:38.698146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-17 06:36:38.698163: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-17 06:36:39.542059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-17 06:36:39.542144: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-17 06:36:39.542153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
      "252872794/252872794 [==============================] - 5s 0us/step\n",
      "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
      "13510573713/13510573713 [==============================] - 248s 0us/step\n",
      "Downloading data from http://images.cocodataset.org/zips/val2014.zip\n",
      "6645013297/6645013297 [==============================] - 171s 0us/step\n"
     ]
    }
   ],
   "source": [
    "%cd CLIP_prefix_caption/\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Download caption annotation files\n",
    "annotation_folder = './data/coco/annotations/'\n",
    "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
    "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
    "                                           extract=True)\n",
    "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
    "  os.remove(annotation_zip)\n",
    "\n",
    "# Download train image files\n",
    "image_folder = './data/coco/train2014/'\n",
    "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
    "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='http://images.cocodataset.org/zips/train2014.zip',\n",
    "                                      extract=True)\n",
    "  PATH = os.path.dirname(image_zip) + image_folder\n",
    "  os.remove(image_zip)\n",
    "else:\n",
    "  PATH = os.path.abspath('.') + image_folder\n",
    "\n",
    "# Download val image files\n",
    "image_folder = './data/coco/val2014/'\n",
    "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
    "  image_zip = tf.keras.utils.get_file('val2014.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='http://images.cocodataset.org/zips/val2014.zip',\n",
    "                                      extract=True)\n",
    "  PATH = os.path.dirname(image_zip) + image_folder\n",
    "  os.remove(image_zip)\n",
    "else:\n",
    "  PATH = os.path.abspath('.') + image_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBJ0Tab4hKEc",
    "outputId": "6680f38e-b7ae-4e02-e69c-5860047bac22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'val2014/COCO_val2014_000000391895.jpg', 'captions': ['A man with a red helmet on a small moped on a dirt road. ', 'Man riding a motor bike on a dirt road on the countryside.', 'A man riding on the back of a motorcycle.', 'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', 'A man in a red shirt and a red hat is on a motorcycle on a hill side.'], 'id': 391895, 'caption_ko': ['빨간 헬멧을 쓴 남자가 작은 모터 달린 비포장 도로를 달려 있다.', '시골의 비포장 도로에서 오토바이를 타는 남자', '오토바이 뒤에 탄 남자', '오토바이 위에 젊은이가 탄 비포장 도로는 다리가 있는 초록빛 지역의 전경과 구름 낀 산의 배경이 있다.', '빨간 셔츠와 빨간 모자를 쓴 남자가 언덕 쪽 오토바이 위에 있다.']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tqdm\n",
    "\n",
    "all_embeddings = []\n",
    "all_captions = []\n",
    "\n",
    "with open('MSCOCO_train_val_Korean.json') as json_file:\n",
    "  json_data = json.load(json_file)\n",
    "\n",
    "print(json_data[0])\n",
    "file_path = \"train_caption2.json\"\n",
    "\n",
    "data2 = []\n",
    "num = 0\n",
    "\n",
    "for ii in range(len(json_data)):\n",
    "  for ij in range(5):\n",
    "    data2.append({\n",
    "      'image_id': json_data[ii]['file_path'].split('_')[2][6:12],\n",
    "      'caption' : json_data[ii]['caption_ko'][ij],\n",
    "      'clip_embedding' : num \n",
    "    })\n",
    "    num += 1\n",
    "with open(file_path, 'w') as outfile:\n",
    "    json.dump(data2, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "zxfIm9YUe45T",
    "outputId": "8d2de75d-c531-4602-95d3-613040524fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i15project23\n",
      "Requirement already satisfied: scikit-image in ./anaconda3/envs/test1020/lib/python3.7/site-packages (0.19.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (2021.11.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (2.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (23.2)\n",
      "Requirement already satisfied: networkx>=2.2 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (1.21.6)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (9.5.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-image) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/test1020/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/envs/test1020/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
      "616435 captions loaded from json \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 616435/616435 [3:19:13<00:00, 51.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "616435 embeddings saved \n",
      "train_num : -152520val_num : 202520\n"
     ]
    }
   ],
   "source": [
    "%cd \n",
    "\n",
    "!pip install scikit-image\n",
    "!pip install scikit-learn\n",
    "\n",
    "import torch\n",
    "import skimage.io as io\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def main():\n",
    "    val_num = 0\n",
    "    device = torch.device('cuda:0')\n",
    "    out_path = \"./data/coco/oscar_split_train.pkl\"\n",
    "    clip_model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
    "    #with open('./data/coco/annotations/train_caption.json', 'r') as f:\n",
    "    with open('train_caption2.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data = shuffle(data)\n",
    "    print(\"%0d captions loaded from json \" % len(data))\n",
    "    all_embeddings = []\n",
    "    all_captions = []\n",
    "    #for i in tqdm(range(len(data))):\n",
    "    for i in tqdm(range(len(data))):\n",
    "        d = data[i]\n",
    "        img_id = d[\"image_id\"]\n",
    "        filename = f\"./train2014/COCO_train2014_{int(img_id):012d}.jpg\"\n",
    "        if not os.path.isfile(filename):\n",
    "            filename = f\"./val2014/COCO_val2014_{int(img_id):012d}.jpg\"\n",
    "            val_num += 1\n",
    "        image = io.imread(filename)\n",
    "        image = preprocess(Image.fromarray(image)).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prefix = clip_model.encode_image(image).cpu()\n",
    "          \n",
    "        d[\"clip_embedding\"] = i\n",
    "        all_embeddings.append(prefix)\n",
    "        all_captions.append(d)\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            with open(out_path, 'wb') as f:\n",
    "                pickle.dump({\"clip_embedding\": torch.cat(all_embeddings, dim=0), \"captions\": all_captions}, f)\n",
    "\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump({\"clip_embedding\": torch.cat(all_embeddings, dim=0), \"captions\": all_captions}, f)\n",
    "\n",
    "    print('Done')\n",
    "    print(\"%0d embeddings saved \" % len(all_embeddings))\n",
    "    print('train_num : ' + str(50000 - val_num) + 'val_num : ' +str(val_num))\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    exit(main())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "captioning_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
